# Cache Memory & Locality

## Cache Memory
- CPU와 메인 메모리(RAM) 사이의 속도 차이를 줄이기 위해 존재하는 계층적 메모리
- CPU는 매우 빠른 속도로 동작하지만, 메인 메모리 접근은 상대적으로 느림 ➡️ CPU가 메모리 대기 시간으로 쉬지 않도록 캐시를 둠
- 일반적으로 SRAM 기반으로 만들어져 DRAM 기반인 RAM보다 빠름
    - SRAM:
        - 데이터가 유지되는 동안 전원이 공급되면 값이 계속 저장됨 (리프레시 필요 X)
        - 속도가 빠름 (CPU 캐시에 사용)
    - DRAM:
        - 시간이 지나면 전하가 방전 (주기적으로 리프레시 필요)
        - 속도가 SRAM보다 느림
- 계층 구조
    - L1 Cache: 
        - CPU 코어에 가장 가까움.
        - 매우 작고 빠름 (수십 KB 수준)

    - L2 Cache:
        - L1보다 큼.
        - 속도는 조금 느림 (수백 KB ~ 수 MB)
    - L3 Cache:
        - 여러 코어가 공유하는 캐시.
        - 크기는 크고 속도는 더 느림 (수 MB 이상)
- Cache Miss
    - CPU가 필요한 데이터가 캐시에 없는 경우 RAM에서 불러와야 함 ➡️ 성능 저하 발생
    - 종류:
        - Cold Miss:
            - 처음 접근하는 데이터라 생기는 미스
        - Capacity Miss:
            - 캐시 공간 부족으로 밀려나 발생
        - Conflict Miss:
            - 매핑 방식 때문에 충돌해서 발생

</br>

## Locality
- 캐시가 효과적인 이유는 프로그램이 데이터에 접근하는 패턴이 특정한 경향(지역성)을 가지기 때문임.
1. 시간 지역성 (Temporal Locality)
    - 최근에 접근한 데이터나 명령어는 곧 다시 접근될 가능성이 높음
    - 예: 반복문에서 같은 변수를 여러 번 사용
2. 공간 지역성 (Spatial Locality)
    - 특정 주소에 접근했다면, 그 주변 주소에도 곧 접근할 가능성이 높음
    - 예: 배열을 순차적으로 탐색
3. 순차적 지역성 (Sequential Locality)
    - 프로그램이 순차적으로 실행되는 특성 때문에, 다음 명령어나 데이터는 현재 것의 바로 옆일 가능성이 높음
    - 사실상 공간 지역성의 특수한 형태



👉 왜??
- 캐시 메모리가 왜 필요할까?
    - CPU-메모리 속도 차이를 줄이기 위해

- 지역성 원리가 캐시와 어떤 관련이 있을까?
    - 캐시는 지역성(시간/공간)에 기반해 자주 쓰이는 데이터가 캐시에 유지되도록 설계됨